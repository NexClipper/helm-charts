# Values for configuring the deployment of TimescaleDB
# The charts README is at:
#    https://github.com/timescale/timescaledb-kubernetes/tree/master/charts/timescaledb-single
# Check out the various configuration options (administration guide) at:
#    https://github.com/timescale/timescaledb-kubernetes/blob/master/charts/timescaledb-single/admin-guide.md
cli: false
timescaledb-single:
  # disable the chart if an existing TimescaleDB instance is used
  enabled: true
  image:
    repository: public.ecr.aws/nexclipper/timescaledb-ha
    tag: pg12-ts2.1-latest
  # create only a ClusterIP service
  loadBalancer:
    enabled: false
  # number or TimescaleDB pods to spawn (default is 3, 1 for no HA)
  replicaCount: 1
    # backup is disabled by default, enable it
  # if you want to backup timescaleDB to s3
  # you can provide the s3 details on tobs install
  # in the user prompt or you can set s3 details in the
  # env variables for the following keys:
  # PGBACKREST_REPO1_S3_BUCKET
  # PGBACKREST_REPO1_S3_ENDPOINT
  # PGBACKREST_REPO1_S3_REGION
  # PGBACKREST_REPO1_S3_KEY
  # PGBACKREST_REPO1_S3_KEY_SECRET
  backup:
    enabled: false
  persistentVolumes:
    data:
      enabled: false
      # size: 10Gi
    wal:
      enabled: false
      # size: 10Gi

loki-stack:
  enabled: true
  loki:
    enabled: true
  fluent-bit:
    enabled: true
  promtail:
    enabled: false
  grafana:
    enabled: false
    sidecar:
      datasources:
        enabled: false
    image:
      tag: 6.7.0

# Values for configuring the deployment of the Promscale Connector
# The charts README is at:
#   https://github.com/timescale/promscale/tree/master/helm-chart
promscale:
  enabled: true
  image: public.ecr.aws/nexclipper/promscale:0.3.0
  # connection options
  connection:
    # the db name in which the metrics will be stored
    dbName: &metricDB postgres
    # user to connect to TimescaleDB with
    user: postgres
    password:
      # Name of a secret object (templated) containing the connection password
      # Key must be value of promscale.connection.user
      # Created by default if timescaledb-single.enabled=true
      secretTemplate: &dbPassSecret "{{ .Release.Name }}-credentials"
      timescaleDBSuperUserKey: PATRONI_SUPERUSER_PASSWORD
    host:
      # Host name (templated) of the database instance, default
      # to service created in timescaledb-single
      nameTemplate: &dbHost "{{ .Release.Name }}.{{ .Release.Namespace }}.svc.cluster.local"
    port: 5432

  # configuration options for the service exposed by promscale
  service:
    # we disable the load balancer by default, only a ClusterIP service
    # will get created
    loadBalancer:
      enabled: false
    nodePort:
      enabled: false
      port: 30000 
  resources:
    requests:
      # By default this should be enough for a cluster
      # with only a few pods
      memory: 1Gi
      cpu: 0.5
# Values for configuring the deployment of Prometheus
# The Prometheus chart from the prometheus-community is used
# the guide for it can be found at:
#   https://artifacthub.io/packages/helm/prometheus-community/prometheus
# with the default values documented at:
#   https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus/values.yaml
prometheus:
  enabled: true
  nodeExporter:
    image:
      repository: quay.io/prometheus/node-exporter
      tag: v1.0.1
    hostRootFsMount: false
  alertmanager:
    persistentVolume:
      enabled: false
    enabled: true
    image:
      repository: quay.io/prometheus/alertmanager
      tag: v0.21.0
  alertmanagerFiles:
    alertmanager.yml:
      route:
        # When a new group of alerts is created by an incoming alert, wait at
        # least 'group_wait' to send the initial notification.
        # This way ensures that you get multiple alerts for the same group that start
        # firing shortly after another are batched together on the first
        # notification.
        group_wait: 10s
        # When the first notification was sent, wait 'group_interval' to send a batch
        # of new alerts that started firing for that group.
        group_interval: 30s
        # If an alert has successfully been sent, wait 'repeat_interval' to
        # resend them.
        repeat_interval: 30m
        # A default receiver
        receiver: "slack"
        # All the above attributes are inherited by all child routes and can
        # overwritten on each.
        routes:
          - receiver: "slack"
            group_wait: 10s
            match_re:
              severity: critical|warning
            continue: true
      receivers:
        - name: "slack"
          slack_configs:
            - api_url: 'https://hooks.slack.com/services/XXXXXXXXX/XXXXXXXXX/xxxxxxxxxxxxxxxxxxxxxxxxxxx'
              send_resolved: true
              channel: 'monitoring'
              text: "{{ range .Alerts }}<!channel> {{ .Annotations.summary }}\n{{ .Annotations.description }}\n{{ end }}"
  pushgateway:
    image:
      repository: quay.io/prometheus/pushgateway
      tag: v1.2.0
    enabled: true
  configmapReload:
    prometheus:
      image:
        repository: public.ecr.aws/nexclipper/configmap-reload
        tag: v0.5.0
  serverFiles:
    alerting_rules.yml:
      groups:
      - name: ExampleRedisGroup
        rules:
        - alert: ExampleRedisDown
          expr: redis_up{} == 0
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Redis instance down"
            description: "Whatever"
    recording_rules.yml:
      groups:
      - name: example_recording_rules
        interval: 60s
        rules:
          - record: node_exporter:node_filesystem_free:fs_used_percents
            expr: 100 - 100 * ( node_filesystem_free{mountpoint="/"} / node_filesystem_size{mountpoint="/"} )
          - record: node_exporter:node_memory_free:memory_used_percents
            expr: 100 - 100 * (node_memory_MemFree / node_memory_MemTotal)
  server:
    # during the upgrades rollingUpdate is creating chaos
    # as both old & new pod try to mount same PVC. So we use
    # Prometheus upgrade strategy as Recreate
    strategy:
      type: Recreate
    persistentVolume:
      enabled: false
    image:
      repository: quay.io/prometheus/prometheus
      tag: v2.24.0
    # we provide a config map which will have the
    # promscale connector already configured as
    # a remote endpoint for read/write (if enabled)
    # this overrides the config map the prometheus chart
    # creates
    configMapOverrideName: "prometheus-config"
    # values to be used in the override config map
    # for a Promscale remote_write and remote_read config
    timescaleRemote:
      # templated
      host: "{{ .Release.Name }}-promscale-connector.{{ .Release.Namespace }}.svc.cluster.local"
      protocol: http
      port: "9201"
      write:
        enabled: true
        # complete url = {protocol}://{host}:{port}/{endpoint}
        endpoint: "write"
        # write queue config
        # see: https://prometheus.io/docs/practices/remote_write/
        queue:
          max_shards: 30
      read:
        enabled: true
        # complete url = {protocol}://{host}:{port}/endpoint
        endpoint: "read"
        read_recent: true
  #You can add other configs from https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus/values.yaml here
  #For example, adding additional scrape jobs
  #extraScrapeConfigs: |
    #example of adding hypotetical scrape job for https://github.com/AICoE/prometheus-anomaly-detector
    #- job_name: prometheus-anomaly
    #  static_configs:
    #    - targets:
    #      - prometheus-anomaly-svc.default:8080
  extraScrapeConfigs: |
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: nexclipper-exporter
      scheme: http
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: nexclipper;exporterhub
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_pod_label_managed
      - action: replace
        source_labels: [__meta_kubernetes_pod_label_app]
        target_label: component
      - action: replace
        source_labels: [__meta_kubernetes_pod_label_managed]
        target_label: managed_by
      - action: replace
        source_labels: [__meta_kubernetes_pod_node_name]
        target_label: kubernetes_node
      - action: replace
        source_labels: [__meta_kubernetes_pod_controller_kind]
        target_label: kubernetes_kind
      - action: replace
        source_labels: [__meta_kubernetes_pod_name]
        target_label: kubernetes_pod_name
      - action: replace
        source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
# Values for configuring the deployment of Grafana
# The Grafana Community chart is used and the guide for it
# can be found at:
#   https://github.com/grafana/helm-charts/blob/main/charts/grafana/README.md
grafana:
  grafana.ini:
    auth.proxy:
      enabled: true
      header_name: X-WEBAUTH-USE
    users:
      allow_sign_up: false      
  image:
    repository: public.ecr.aws/nexclipper/grafana
    tag: 7.4.2
  sidecar:
    image:
      repository: public.ecr.aws/nexclipper/k8s-sidecar
      tag: 1.10.6
    datasources:
      enabled: true
    dashboards:
      enabled: true
      files:
        - dashboards/k8s-cluster.json
        - dashboards/k8s-hardware.json
        - dashboards/k8s-cluster-kr.json
        - dashboards/node-exporter.json
  envFromSecret: "{{ .Release.Name }}-grafana-db"
  initChownData:
    image:
      repository: public.ecr.aws/nexclipper/busybox
      tag: "1.28"
  loki:
    datasource:
      enabled: true
      url: "http://{{ .Release.Name }}-loki.{{ .Release.Namespace }}.svc.cluster.local:3100"
  prometheus:
    datasource:
      enabled: true
      # By default url of data source is set to ts-prom connector instance
      # deployed with this chart. If a connector isn't used this should be
      # set to the prometheus-server.
      url: "http://{{ .Release.Name }}-promscale-connector.{{ .Release.Namespace }}.svc.cluster.local:9201"
  timescale:
    database:
      enabled: true
      host:  *dbHost
      port: 5432
      user: grafanadb
      pass: grafanadb
      dbName: *metricDB
      schema: grafanadb
      sslMode: require
    datasource:
      enabled: true
      user: grafana
      pass: grafana
      dbName: *metricDB
      sslMode: require
      # By default the url/host is set to the db instance deployed
      # with this chart
      host: *dbHost
      port: 5432
    adminUser: postgres
    adminPassSecret: *dbPassSecret

grafanaDBJob:
  resources: {}

#Enable PromLens  https://promlens.com/
#PromLens is a PromQL query builder, analyzer, and visualizer
promlens:
  enabled: true
  image: "public.ecr.aws/nexclipper/promlens:latest"
  # This default URL assumes access via port-forwarding to the connector. If using
  # a load balancer for the connector, change as appropriate
  # NOTE: the internal cluster address does not work here as requests are made by the browser.
  defaultPrometheusUrl:  "http://localhost:9201"
  licenseKey: ""
  license:
    enabled: false
  loadBalancer:
    enabled: false

#Enable Promscale to connect to an existing database by providing the db-uri
timescaledbExternal:
  enabled: false
  db_uri: ""
